import cv2
import numpy as np
import time
import os
# Hailo SDKë¥¼ ì‚¬ìš©í•˜ì—¬ HEF íŒŒì¼ì„ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.
# ì‹¤ì œ í™˜ê²½ì— ë§ê²Œ hailo_sdk_client ë˜ëŠ” HailoRT ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
# from hailo_sdk_client import ClientRunner # (ì˜ˆì‹œ)

# --- 1. í™˜ê²½ ì„¤ì • ë° HEF ëª¨ë¸ ê²½ë¡œ ---
# âš ï¸ HEF íŒŒì¼ ê²½ë¡œë¥¼ ì‹¤ì œ ê²½ë¡œë¡œ ìˆ˜ì •í•˜ì„¸ìš”.
HEF_FILES = {
    'pose': 'pose_model.hef',
    'parsing': 'parsing_model.hef',
    'generator': 'hr_viton_generator.hef'
}

# âš ï¸ Generatorê°€ ê¸°ëŒ€í•˜ëŠ” ê³ ì • ì…ë ¥ í¬ê¸° (ì´ì „ ë…¼ì˜ ê¸°ì¤€)
INPUT_H, INPUT_W = 256, 192 
# âš ï¸ Warper ì—°ì‚°ì— í•„ìš”í•œ ì˜· ì´ë¯¸ì§€ (ë¯¸ë¦¬ ë¡œë“œí•´ì•¼ í•©ë‹ˆë‹¤)
CLOTH_IMAGE_PATH = 'target_cloth.jpg' 

# --- 2. Warper ì—°ì‚° (RPi 5 CPU ë³‘ëª© ì§€ì ) ---
def run_warper_on_cpu(image_np, parsing_mask, keypoints):
    """
    RPi 5 CPUì—ì„œ ì‹¤í–‰ë˜ëŠ” Warper ë¡œì§ì…ë‹ˆë‹¤.
    TPS ë³€í™˜ ë˜ëŠ” Flow Field ì˜ˆì¸¡ì„ ì‚¬ìš©í•˜ì—¬ ì˜· ì´ë¯¸ì§€ë¥¼ ë³€í˜•í•©ë‹ˆë‹¤.
    (ì´ í•¨ìˆ˜ëŠ” ì‚¬ìš©ìì˜ HR-VITON ì½”ë“œì— ë§ê²Œ êµ¬í˜„ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.)
    """
    # 1. ì˜· ì´ë¯¸ì§€ ë¡œë“œ (í˜¹ì€ ì „ì—­ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
    cloth = cv2.imread(CLOTH_IMAGE_PATH)
    if cloth is None:
        raise FileNotFoundError("Cloth image not found for Warper.")
    cloth = cv2.resize(cloth, (INPUT_W, INPUT_H))

    # 2. **ì‹¤ì œ Warping ë¡œì§ êµ¬í˜„ í•„ìš”**: 
    #    (ì˜ˆ: TPS, torch.nn.functional.grid_sample ë¡œì§ì„ numpy/opencvë¡œ ë³€í™˜)
    
    # ğŸš§ í˜„ì¬ëŠ” ë”ë¯¸ ë°ì´í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
    warped_cloth = cloth * 0.5 + image_np * 0.5 
    
    # Warped cloth í…ì„œ (3, H, W) í˜•íƒœë¡œ ë°˜í™˜
    return warped_cloth.astype(np.float32) / 255.0

# --- 3. Hailo Inference Pipeline (ì¶”ë¡  ê´€ë¦¬) ---
class VTO_Pipeline:
    def __init__(self):
        # âš ï¸ ì‹¤ì œ Hailo SDK ì´ˆê¸°í™” ì½”ë“œë¡œ ëŒ€ì²´í•´ì•¼ í•©ë‹ˆë‹¤.
        print("Initializing Hailo models...")
        # self.pose_runner = ClientRunner(HEF_FILES['pose'], ...)
        # self.parsing_runner = ClientRunner(HEF_FILES['parsing'], ...)
        # self.generator_runner = ClientRunner(HEF_FILES['generator'], ...)
        
        self.cloth_image = cv2.imread(CLOTH_IMAGE_PATH)
        self.cloth_image = cv2.resize(self.cloth_image, (INPUT_W, INPUT_H))
        
        print("Hailo models initialized (Conceptual).")
        
    def preprocess_image(self, frame):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (RPi 5 CPU)"""
        resized_frame = cv2.resize(frame, (INPUT_W, INPUT_H))
        # BGR -> RGB ë° ì •ê·œí™” (ëª¨ë¸ ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ)
        norm_frame = resized_frame.astype(np.float32) / 255.0
        return norm_frame
    
    def infer_hailo(self, runner, input_data):
        """Hailo ëª¨ë¸ ì¶”ë¡  (Conceptual)"""
        # âš ï¸ ì‹¤ì œ Hailo SDK ì¶”ë¡  ì½”ë“œë¡œ ëŒ€ì²´í•´ì•¼ í•©ë‹ˆë‹¤.
        # output = runner.infer(input_data)
        
        # ğŸš§ í˜„ì¬ëŠ” ë”ë¯¸ ë°ì´í„°ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.
        if 'pose' in runner:
            return {'keypoints': np.random.rand(1, 18, 2)}
        elif 'parsing' in runner:
            return {'semantic_map': np.zeros((1, 7, INPUT_H, INPUT_W))}
        
    def run(self, frame):
        # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (RPi 5 CPU)
        norm_frame = self.preprocess_image(frame)
        
        # 2. Pose & Parsing ì¶”ë¡  (HAILO ê°€ì†)
        # âš ï¸ ì‹¤ì œë¡œëŠ” RPi 5ê°€ Hailoë¡œ ë°ì´í„°ë¥¼ ë³´ë‚´ê³  ê²°ê³¼ë¥¼ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        pose_output = self.infer_hailo('pose', norm_frame)
        parsing_output = self.infer_hailo('parsing', norm_frame)
        
        semantics = parsing_output['semantic_map']
        keypoints = pose_output['keypoints']
        
        # 3. Warper ì—°ì‚° (RPi 5 CPU ë³‘ëª© ì§€ì )
        warped_cloth = run_warper_on_cpu(norm_frame, semantics, keypoints)
        
        # 4. Generator ì…ë ¥ ì¤€ë¹„ (Agnostic Image ìƒì„± í•„ìš” - ìƒëµ)
        #    HR-VITONì€ Semantic Map, Warped Cloth, Agnostic Image 3ê°œë¥¼ ìš”êµ¬í•©ë‹ˆë‹¤.
        
        # 5. Generator ì¶”ë¡  (HAILO ê°€ì†)
        # âš ï¸ Warped Cloth, Semantics, Agnostic Imageë¥¼ Hailoë¡œ ë³´ëƒ„
        # input_tensors = [semantics, warped_cloth, agnostic_image]
        generated_tensor = self.infer_hailo('generator', [warped_cloth, semantics, norm_frame]) # norm_frameì„ Agnostic Imageë¡œ ì„ì‹œ ì‚¬ìš©
        
        # 6. í›„ì²˜ë¦¬
        generated_image = generated_tensor[0] # (H, W, 3)
        generated_image = (generated_image * 255).astype(np.uint8)
        
        return generated_image

# --- 4. ë©”ì¸ ë£¨í”„ (ì‹¤í–‰) ---
def main():
    # 0ì„ ì‚¬ìš©í•˜ë©´ /dev/video0ì„ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤.
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("ERROR: Could not open camera (/dev/video0).")
        return
        
    # VTO íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” (Hailo ëª¨ë¸ ë¡œë“œ)
    try:
        pipeline = VTO_Pipeline()
    except Exception as e:
        print(f"Error during pipeline initialization: {e}")
        return

    print("Starting real-time VTO inference. Press 'q' to exit.")
    
    while True:
        ret, frame = cap.read()
        if not ret:
            print("Cannot receive frame (stream end?). Exiting ...")
            break

        start_time = time.time()
        
        # VTO ì¶”ë¡  ì‹¤í–‰
        result_frame = pipeline.run(frame)
        
        end_time = time.time()
        fps = 1.0 / (end_time - start_time)

        # FPS í‘œì‹œ
        cv2.putText(result_frame, f'FPS: {fps:.2f}', (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
        
        # ê²°ê³¼ í™”ë©´ ì¶œë ¥
        # ì›ë³¸ í”„ë ˆì„ê³¼ ê²°ê³¼ë¥¼ ê°€ë¡œë¡œ ë¶™ì—¬ì„œ ë³´ì—¬ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        display_frame = cv2.hconcat([cv2.resize(frame, (INPUT_W, INPUT_H)), result_frame])
        
        cv2.imshow('Real-time Virtual Try-On (Hailo Hybrid)', display_frame)

        if cv2.waitKey(1) == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()
